{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# A agent at any time has the following state\n",
    "#  pos : int\n",
    "#  health : int (>=0)\n",
    "class AgentState:\n",
    "    def __init__(self, pos, health):\n",
    "        self.pos = pos\n",
    "        self.health = health\n",
    "\n",
    "# A game has the following state at any time. The state is visiable to both agents\n",
    "#  state of agent_0\n",
    "#  state of agent_1\n",
    "class GameState:                \n",
    "    def __init__(self, agent_0_state, agent_1_state):\n",
    "        self.agents = [agent_0_state, agent_1_state]\n",
    "        \n",
    "    def __str__(self):\n",
    "     return str(self.agents[0].pos) + \",\" + str(self.agents[0].health) + \",\" + str(self.agents[1].pos) + \",\" + str(self.agents[1].health)\n",
    "\n",
    "# at any time in a game, a agent can take one of the following actions\n",
    "class GameAction:\n",
    "    MOVELEFT = 1\n",
    "    MOVERIGHT = 2\n",
    "    ATTACK = 3\n",
    "        \n",
    "# The simulator manges the following\n",
    "#   the game state at any time\n",
    "#   reward judgment\n",
    "class GameSimulator:\n",
    "    def __init__(self):\n",
    "        # init the game state (start of a game)\n",
    "        self.init_health = 3\n",
    "        self.init_pos_0 = 5\n",
    "        self.init_pos_1 = 7\n",
    "        self.miss_rate = 0.1\n",
    "        self.move_speed = 1\n",
    "        self.attack_power = 1\n",
    "        self.attack_range = 1\n",
    "        self.final_award = 100\n",
    "        \n",
    "        agent_0 = AgentState(self.init_pos_0, self.init_health)\n",
    "        agent_1 = AgentState(self.init_pos_1, self.init_health)\n",
    "        self.state = GameState(agent_0, agent_1)\n",
    "\n",
    "    \n",
    "    def move_agent(self, agent_idx, agent_action):\n",
    "        # no health no action\n",
    "        if self.state.agents[agent_idx].health <= 0:\n",
    "            return\n",
    "        \n",
    "        opponent_idx = (agent_idx + 1) % 2\n",
    "          # first decide the move actions\n",
    "        if agent_action == GameAction.MOVELEFT:\n",
    "            # no other agent should on the path to the target spot\n",
    "            if self.state.agents[opponent_idx].pos >= self.state.agents[agent_idx].pos - self.move_speed and \\\n",
    "            self.state.agents[opponent_idx].pos <= self.state.agents[agent_idx].pos :\n",
    "                return\n",
    "            else:\n",
    "                self.state.agents[agent_idx].pos = self.state.agents[agent_idx].pos - self.move_speed\n",
    "        \n",
    "        if agent_action == GameAction.MOVERIGHT:\n",
    "            # no other agent should on the path to the target spot\n",
    "            if self.state.agents[opponent_idx].pos <= self.state.agents[agent_idx].pos + self.move_speed and \\\n",
    "            self.state.agents[opponent_idx].pos >= self.state.agents[agent_idx].pos :\n",
    "                return\n",
    "            else:\n",
    "                self.state.agents[agent_idx].pos = self.state.agents[agent_idx].pos + self.move_speed\n",
    "                \n",
    "        # [Q] should we reward for being closer to the opponent ? \n",
    "    \n",
    "    def attack_agent(self, agent_idx, agent_action):\n",
    "        # no health no action\n",
    "        if self.state.agents[agent_idx].health <= 0:\n",
    "            return\n",
    "        \n",
    "        opponent_idx = (agent_idx + 1) % 2\n",
    "        \n",
    "        if agent_action == GameAction.ATTACK:\n",
    "            # there is a change to miss the hit\n",
    "            hit =  0 if random.random() < self.miss_rate else 1\n",
    "            \n",
    "            # attack is only valid if the two agents are within attach range\n",
    "            if abs(self.state.agents[opponent_idx].pos - self.state.agents[agent_idx].pos) <= self.attack_range:\n",
    "                self.state.agents[opponent_idx].health = self.state.agents[opponent_idx].health - hit * self.attack_power\n",
    "                \n",
    "                # if the opponent still has positive health, reward by attack power\n",
    "                # if the opponent has zero or negative health, reward by final reward\n",
    "                if self.state.agents[opponent_idx].health > 0:\n",
    "                    return hit * self.attack_power\n",
    "                else:\n",
    "                    return self.final_award\n",
    "        \n",
    "        # no attack action return 0\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    # consider the action of both agent_0 and agent_1, decide the reward to each\n",
    "    def take_action(self, action_0, action_1):\n",
    "        reward_0 = 0\n",
    "        reward_1 = 0\n",
    "      \n",
    "        # first make the move update\n",
    "        who_moves_first = 0 if random.random() < 0.5 else 1\n",
    "        \n",
    "        if who_moves_first == 0: # agent_0 moves first\n",
    "            self.move_agent(0, action_0)\n",
    "            self.move_agent(1, action_1)\n",
    "        else:\n",
    "            self.move_agent(1, action_1)\n",
    "            self.move_agent(0, action_0)\n",
    "        \n",
    "      \n",
    "        # then make the attack update\n",
    "        gain_0 = 0\n",
    "        gain_1 = 0\n",
    "        \n",
    "        who_attacks_first = 0 if random.random() < 0.5 else 1\n",
    "        if who_attacks_first == 0: # agent_0 attacks first\n",
    "            gain_0 = self.attack_agent(0, action_0)\n",
    "            gain_1 = self.attack_agent(1, action_1)\n",
    "        else:\n",
    "            gain_1 = self.attack_agent(1, action_1)\n",
    "            gain_0 = self.attack_agent(0, action_0)\n",
    "        \n",
    "        # if the agent still has positive health, reward is the attack result\n",
    "        # otherwise, the reward is -1 * final_reward\n",
    "        reward_0 = gain_0 if self.state.agents[0].health > 0 else -1 * gain_1\n",
    "        reward_1 = gain_1 if self.state.agents[1].health > 0 else -1 * gain_0\n",
    "        \n",
    "        return self.state, reward_0, reward_1\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset state \n",
    "        agent_0 = AgentState(self.init_pos_0, self.init_health)\n",
    "        agent_1 = AgentState(self.init_pos_1, self.init_health)\n",
    "        self.state = GameState(agent_0, agent_1)\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    def is_finished(self):\n",
    "        # finished when one agent is 0 health\n",
    "        # return the winner\n",
    "        if self.state.agents[0].health <= 0:\n",
    "            return 1\n",
    "        \n",
    "        if self.state.agents[1].health <= 0:\n",
    "            return 0\n",
    "        \n",
    "        return -1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a =[0,0,0,0]\n",
    "\n",
    "max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class AgentClass1:\n",
    "    def __init__(self, learning_rate=0.2, discount=0.95, exploration_rate=1.0):\n",
    "        self.learning_rate = learning_rate # How much we appreciate new q-value over current\n",
    "        self.discount = discount # How much we appreciate future reward over current\n",
    "        self.exploration_rate = 1.0 # Initial exploration rate\n",
    "        self.exploration_decay = 0.01 # Shift from exploration to explotation\n",
    "\n",
    "        self.action_list = [GameAction.MOVELEFT, GameAction.MOVERIGHT, GameAction.ATTACK]\n",
    "        \n",
    "        # q_dict that keeps the reward for each key\n",
    "        # the key is composed of \"agent_0_pos, agent_0_health, agent_1_pos, agent_1_health\"\n",
    "        # the value is a array of size len(self.action_list) represents the reward of each action\n",
    "        self.q_dict = {\"init\" : [0]*len(self.action_list)}\n",
    "        \n",
    "\n",
    "\n",
    "    def get_next_action(self, game_state):\n",
    "        state_key = str(game_state)\n",
    "        \n",
    "        if state_key not in self.q_dict:  # always init the state if not init yet\n",
    "            self.q_dict[state_key] = [0]*len(self.action_list)\n",
    "                \n",
    "        if random.random() > self.exploration_rate: # Explore (gamble) or exploit (greedy)\n",
    "            return self.greedy_action(game_state)\n",
    "        else:\n",
    "            return self.random_action()\n",
    "\n",
    "    def greedy_action(self, game_state):\n",
    "        state_key = str(game_state)\n",
    "        \n",
    "        # randomly pick one from the actions with max reward\n",
    "        max_reward = max(self.q_dict[state_key])\n",
    "        indices = [i for i, x in enumerate(self.q_dict[state_key]) if x == max_reward]\n",
    "        action_idx =random.randrange(len(indices))\n",
    "            \n",
    "        return self.action_list[indices[action_idx]]\n",
    "            \n",
    "\n",
    "    def random_action(self):\n",
    "        return self.action_list[random.randrange(len(self.action_list))]\n",
    "    \n",
    "\n",
    "    def update(self, cur_state, new_state, action, reward):\n",
    "        cur_state_idx = str(cur_state)\n",
    "        new_state_idx = str(new_state)\n",
    "        action_idx = self.action_list.index(action)\n",
    "        \n",
    "        # cur Q-dict value\n",
    "        cur_value = self.q_dict[cur_state_idx][action_idx]\n",
    "        \n",
    "        # What would be our best next action?\n",
    "        if new_state_idx not in self.q_dict: # if future state does not init yet, init it\n",
    "            self.q_dict[new_state_idx] = [0]*len(self.action_list)\n",
    "            \n",
    "        future_reward = max(self.q_dict[new_state_idx])\n",
    "        \n",
    "        # Main Q-table updating algorithm\n",
    "        new_value = cur_value + self.learning_rate * (reward + self.discount * future_reward - cur_value)\n",
    "        self.q_dict[cur_state_idx][action_idx] = new_value\n",
    "\n",
    "        # Finally shift our exploration_rate toward zero (less gambling)\n",
    "        if self.exploration_rate > 0:\n",
    "            self.exploration_rate *= (1 - self.exploration_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"i\": 0, \"o_state\": \"5,3,7,3\", \"n_state\": \"5,3,6,3\", \"a0\": 2, \"1\": 1, \"t_re\": 0, \"0_win\": 0, \"1_win\": 0}\n",
      "{\"i\": 1000, \"o_state\": \"20,2,44,2\", \"n_state\": \"21,2,44,2\", \"a0\": 2, \"1\": 3, \"t_re\": 1, \"0_win\": 0, \"1_win\": 0}\n",
      "{\"i\": 2000, \"o_state\": \"22,2,59,2\", \"n_state\": \"22,2,60,2\", \"a0\": 3, \"1\": 2, \"t_re\": 1, \"0_win\": 0, \"1_win\": 0}\n",
      "{\"i\": 3000, \"o_state\": \"71,2,80,2\", \"n_state\": \"71,2,79,2\", \"a0\": 3, \"1\": 1, \"t_re\": 1, \"0_win\": 0, \"1_win\": 0}\n",
      "{\"i\": 4000, \"o_state\": \"0,3,9,3\", \"n_state\": \"0,3,10,3\", \"a0\": 3, \"1\": 2, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 5000, \"o_state\": \"-30,3,33,3\", \"n_state\": \"-30,3,33,3\", \"a0\": 3, \"1\": 3, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 6000, \"o_state\": \"-38,3,37,3\", \"n_state\": \"-37,3,37,3\", \"a0\": 2, \"1\": 3, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 7000, \"o_state\": \"-25,3,72,3\", \"n_state\": \"-26,3,71,3\", \"a0\": 1, \"1\": 1, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 8000, \"o_state\": \"9,3,64,3\", \"n_state\": \"9,3,63,3\", \"a0\": 3, \"1\": 1, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 9000, \"o_state\": \"-23,3,79,3\", \"n_state\": \"-22,3,80,3\", \"a0\": 2, \"1\": 2, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 10000, \"o_state\": \"-46,3,102,3\", \"n_state\": \"-47,3,102,3\", \"a0\": 1, \"1\": 3, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 11000, \"o_state\": \"-54,3,110,3\", \"n_state\": \"-53,3,111,3\", \"a0\": 2, \"1\": 2, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 12000, \"o_state\": \"-50,3,81,3\", \"n_state\": \"-51,3,80,3\", \"a0\": 1, \"1\": 1, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 13000, \"o_state\": \"-55,3,101,3\", \"n_state\": \"-54,3,101,3\", \"a0\": 2, \"1\": 3, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 14000, \"o_state\": \"-47,3,76,3\", \"n_state\": \"-47,3,77,3\", \"a0\": 3, \"1\": 2, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 15000, \"o_state\": \"-66,3,11,3\", \"n_state\": \"-65,3,10,3\", \"a0\": 2, \"1\": 1, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 16000, \"o_state\": \"-110,3,30,3\", \"n_state\": \"-110,3,30,3\", \"a0\": 3, \"1\": 3, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 17000, \"o_state\": \"-88,3,-35,3\", \"n_state\": \"-88,3,-36,3\", \"a0\": 3, \"1\": 1, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 18000, \"o_state\": \"-111,3,-40,3\", \"n_state\": \"-112,3,-41,3\", \"a0\": 1, \"1\": 1, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 19000, \"o_state\": \"-139,3,-64,3\", \"n_state\": \"-138,3,-65,3\", \"a0\": 2, \"1\": 1, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 20000, \"o_state\": \"-113,3,-66,3\", \"n_state\": \"-112,3,-66,3\", \"a0\": 2, \"1\": 3, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 21000, \"o_state\": \"-121,3,-76,3\", \"n_state\": \"-120,3,-75,3\", \"a0\": 2, \"1\": 2, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 22000, \"o_state\": \"-127,3,-100,3\", \"n_state\": \"-127,3,-100,3\", \"a0\": 3, \"1\": 3, \"t_re\": 617, \"0_win\": 3, \"1_win\": 3}\n",
      "{\"i\": 23000, \"o_state\": \"-4,1,10,3\", \"n_state\": \"-4,1,10,3\", \"a0\": 3, \"1\": 3, \"t_re\": 825, \"0_win\": 5, \"1_win\": 3}\n",
      "{\"i\": 24000, \"o_state\": \"-17,1,27,3\", \"n_state\": \"-17,1,27,3\", \"a0\": 3, \"1\": 3, \"t_re\": 825, \"0_win\": 5, \"1_win\": 3}\n",
      "{\"i\": 25000, \"o_state\": \"-6,1,5,3\", \"n_state\": \"-5,1,6,3\", \"a0\": 2, \"1\": 2, \"t_re\": 825, \"0_win\": 5, \"1_win\": 3}\n",
      "{\"i\": 26000, \"o_state\": \"-32,3,24,1\", \"n_state\": \"-32,3,24,1\", \"a0\": 3, \"1\": 3, \"t_re\": 1234, \"0_win\": 7, \"1_win\": 5}\n",
      "{\"i\": 27000, \"o_state\": \"0,3,11,1\", \"n_state\": \"-1,3,10,1\", \"a0\": 1, \"1\": 1, \"t_re\": 1337, \"0_win\": 8, \"1_win\": 5}\n",
      "{\"i\": 28000, \"o_state\": \"-5,3,20,3\", \"n_state\": \"-6,3,20,3\", \"a0\": 1, \"1\": 3, \"t_re\": 1438, \"0_win\": 9, \"1_win\": 5}\n",
      "{\"i\": 29000, \"o_state\": \"-22,3,-4,3\", \"n_state\": \"-22,3,-3,3\", \"a0\": 3, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 30000, \"o_state\": \"-27,3,-1,3\", \"n_state\": \"-28,3,0,3\", \"a0\": 1, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 31000, \"o_state\": \"-24,3,28,3\", \"n_state\": \"-24,3,27,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 32000, \"o_state\": \"-33,3,36,3\", \"n_state\": \"-32,3,37,3\", \"a0\": 2, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 33000, \"o_state\": \"-49,3,8,3\", \"n_state\": \"-49,3,7,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 34000, \"o_state\": \"-61,3,-6,3\", \"n_state\": \"-62,3,-7,3\", \"a0\": 1, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 35000, \"o_state\": \"-85,3,19,3\", \"n_state\": \"-85,3,20,3\", \"a0\": 3, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 36000, \"o_state\": \"-69,3,34,3\", \"n_state\": \"-68,3,34,3\", \"a0\": 2, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 37000, \"o_state\": \"-50,3,58,3\", \"n_state\": \"-50,3,59,3\", \"a0\": 3, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 38000, \"o_state\": \"-45,3,89,3\", \"n_state\": \"-46,3,88,3\", \"a0\": 1, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 39000, \"o_state\": \"-30,3,62,3\", \"n_state\": \"-29,3,62,3\", \"a0\": 2, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 40000, \"o_state\": \"-55,3,63,3\", \"n_state\": \"-54,3,63,3\", \"a0\": 2, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 41000, \"o_state\": \"-73,3,68,3\", \"n_state\": \"-74,3,68,3\", \"a0\": 1, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 42000, \"o_state\": \"-82,3,54,3\", \"n_state\": \"-81,3,53,3\", \"a0\": 2, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 43000, \"o_state\": \"-117,3,27,3\", \"n_state\": \"-117,3,26,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 44000, \"o_state\": \"-87,3,75,3\", \"n_state\": \"-88,3,75,3\", \"a0\": 1, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 45000, \"o_state\": \"-58,3,115,3\", \"n_state\": \"-57,3,115,3\", \"a0\": 2, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 46000, \"o_state\": \"-26,3,79,3\", \"n_state\": \"-27,3,78,3\", \"a0\": 1, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 47000, \"o_state\": \"-31,3,58,3\", \"n_state\": \"-30,3,57,3\", \"a0\": 2, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 48000, \"o_state\": \"-31,3,34,3\", \"n_state\": \"-30,3,33,3\", \"a0\": 2, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 49000, \"o_state\": \"-23,3,40,3\", \"n_state\": \"-22,3,41,3\", \"a0\": 2, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 50000, \"o_state\": \"-46,3,45,3\", \"n_state\": \"-45,3,44,3\", \"a0\": 2, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 51000, \"o_state\": \"-98,3,60,3\", \"n_state\": \"-99,3,61,3\", \"a0\": 1, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 52000, \"o_state\": \"-112,3,108,3\", \"n_state\": \"-113,3,108,3\", \"a0\": 1, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 53000, \"o_state\": \"-129,3,92,3\", \"n_state\": \"-128,3,92,3\", \"a0\": 2, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 54000, \"o_state\": \"-151,3,103,3\", \"n_state\": \"-151,3,104,3\", \"a0\": 3, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 55000, \"o_state\": \"-146,3,134,3\", \"n_state\": \"-145,3,134,3\", \"a0\": 2, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 56000, \"o_state\": \"-163,3,158,3\", \"n_state\": \"-162,3,158,3\", \"a0\": 2, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 57000, \"o_state\": \"-187,3,185,3\", \"n_state\": \"-188,3,185,3\", \"a0\": 1, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 58000, \"o_state\": \"-134,3,197,3\", \"n_state\": \"-134,3,197,3\", \"a0\": 3, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 59000, \"o_state\": \"-112,3,166,3\", \"n_state\": \"-113,3,166,3\", \"a0\": 1, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 60000, \"o_state\": \"-119,3,136,3\", \"n_state\": \"-118,3,137,3\", \"a0\": 2, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 61000, \"o_state\": \"-110,3,144,3\", \"n_state\": \"-110,3,143,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 62000, \"o_state\": \"-44,3,145,3\", \"n_state\": \"-44,3,146,3\", \"a0\": 3, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 63000, \"o_state\": \"-15,3,162,3\", \"n_state\": \"-15,3,163,3\", \"a0\": 3, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 64000, \"o_state\": \"-48,3,192,3\", \"n_state\": \"-49,3,193,3\", \"a0\": 1, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 65000, \"o_state\": \"-22,3,200,3\", \"n_state\": \"-23,3,200,3\", \"a0\": 1, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 66000, \"o_state\": \"-70,3,192,3\", \"n_state\": \"-70,3,192,3\", \"a0\": 3, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 67000, \"o_state\": \"-50,3,185,3\", \"n_state\": \"-50,3,184,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 68000, \"o_state\": \"-53,3,156,3\", \"n_state\": \"-54,3,157,3\", \"a0\": 1, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 69000, \"o_state\": \"-38,3,150,3\", \"n_state\": \"-37,3,149,3\", \"a0\": 2, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 70000, \"o_state\": \"-81,3,152,3\", \"n_state\": \"-81,3,152,3\", \"a0\": 3, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 71000, \"o_state\": \"-64,3,137,3\", \"n_state\": \"-65,3,138,3\", \"a0\": 1, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 72000, \"o_state\": \"-74,3,155,3\", \"n_state\": \"-74,3,155,3\", \"a0\": 3, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 73000, \"o_state\": \"-78,3,136,3\", \"n_state\": \"-77,3,136,3\", \"a0\": 2, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 74000, \"o_state\": \"-95,3,133,3\", \"n_state\": \"-95,3,134,3\", \"a0\": 3, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 75000, \"o_state\": \"-48,3,141,3\", \"n_state\": \"-47,3,142,3\", \"a0\": 2, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 76000, \"o_state\": \"-97,3,170,3\", \"n_state\": \"-96,3,169,3\", \"a0\": 2, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 77000, \"o_state\": \"-95,3,113,3\", \"n_state\": \"-95,3,112,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 78000, \"o_state\": \"-86,3,99,3\", \"n_state\": \"-86,3,98,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 79000, \"o_state\": \"-64,3,108,3\", \"n_state\": \"-65,3,107,3\", \"a0\": 1, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 80000, \"o_state\": \"-23,3,124,3\", \"n_state\": \"-23,3,123,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 81000, \"o_state\": \"-101,3,152,3\", \"n_state\": \"-102,3,153,3\", \"a0\": 1, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 82000, \"o_state\": \"-53,3,192,3\", \"n_state\": \"-54,3,193,3\", \"a0\": 1, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 83000, \"o_state\": \"-21,3,218,3\", \"n_state\": \"-21,3,217,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 84000, \"o_state\": \"-14,3,189,3\", \"n_state\": \"-15,3,190,3\", \"a0\": 1, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 85000, \"o_state\": \"-23,3,214,3\", \"n_state\": \"-23,3,215,3\", \"a0\": 3, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 86000, \"o_state\": \"-38,3,201,3\", \"n_state\": \"-39,3,200,3\", \"a0\": 1, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 87000, \"o_state\": \"-7,3,206,3\", \"n_state\": \"-6,3,207,3\", \"a0\": 2, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 88000, \"o_state\": \"22,3,256,3\", \"n_state\": \"22,3,256,3\", \"a0\": 3, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 89000, \"o_state\": \"47,3,290,3\", \"n_state\": \"47,3,289,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 90000, \"o_state\": \"49,3,300,3\", \"n_state\": \"49,3,300,3\", \"a0\": 3, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 91000, \"o_state\": \"53,3,286,3\", \"n_state\": \"53,3,286,3\", \"a0\": 3, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 92000, \"o_state\": \"53,3,258,3\", \"n_state\": \"52,3,257,3\", \"a0\": 1, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 93000, \"o_state\": \"52,3,275,3\", \"n_state\": \"53,3,275,3\", \"a0\": 2, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 94000, \"o_state\": \"21,3,309,3\", \"n_state\": \"21,3,308,3\", \"a0\": 3, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 95000, \"o_state\": \"25,3,298,3\", \"n_state\": \"24,3,297,3\", \"a0\": 1, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 96000, \"o_state\": \"-10,3,337,3\", \"n_state\": \"-9,3,336,3\", \"a0\": 2, \"1\": 1, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 97000, \"o_state\": \"-60,3,393,3\", \"n_state\": \"-60,3,394,3\", \"a0\": 3, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 98000, \"o_state\": \"-62,3,389,3\", \"n_state\": \"-63,3,389,3\", \"a0\": 1, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 99000, \"o_state\": \"-45,3,367,3\", \"n_state\": \"-45,3,367,3\", \"a0\": 3, \"1\": 3, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n",
      "{\"i\": 99999, \"o_state\": \"-86,3,369,3\", \"n_state\": \"-85,3,370,3\", \"a0\": 2, \"1\": 2, \"t_re\": 1849, \"0_win\": 12, \"1_win\": 6}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# parse arguments\n",
    "iterations = 100000\n",
    "    \n",
    "# setup simulation\n",
    "master = GameSimulator()\n",
    "master.reset()\n",
    "total_reward = 0 # Score keeping\n",
    "    \n",
    "# setup agents\n",
    "agent_0 = AgentClass1()\n",
    "agent_1 = AgentClass1()\n",
    "\n",
    "agent_0_win = 0\n",
    "agent_1_win = 0\n",
    "\n",
    "# main loop\n",
    "for step in range(iterations):\n",
    "    old_state = copy.deepcopy(master.state) # Store current state\n",
    "    \n",
    "    action_0 = agent_0.get_next_action(old_state) # Query agent for the next action\n",
    "    action_1 = agent_1.get_next_action(old_state)\n",
    "        \n",
    "    new_state, reward_0, reward_1 = master.take_action(action_0, action_1) # Take action, get new state and reward\n",
    "        \n",
    "    agent_0.update(old_state, new_state, action_0, reward_0) \n",
    "    agent_1.update(old_state, new_state, action_1, reward_1) \n",
    "\n",
    "    total_reward += max(reward_0, reward_1) # Keep score\n",
    "    \n",
    "    winner = master.is_finished()\n",
    "    \n",
    "    if winner >= 0 :  # game is finished with winner\n",
    "        if winner == 0:\n",
    "            agent_0_win += 1\n",
    "        if winner == 1:\n",
    "            agent_1_win += 1\n",
    "        \n",
    "        # reset to start a new game\n",
    "        master.reset()\n",
    "            \n",
    "    \n",
    "    if step % 1000 == 0 or step == iterations - 1 :\n",
    "        print(json.dumps({'i': step, \"o_state\": str(old_state), \"n_state\": str(new_state), \"a0\": action_0, \"1\": action_1, 't_re': total_reward, '0_win': agent_0_win, '1_win': agent_1_win}))\n",
    "\n",
    "    time.sleep(0.0001) # Avoid spamming stdout too fast!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"state\": \"5,3,7,3\", \"action_reward\": [0.15917692045438483, 0.0, 0.2]}\n",
      "{\"state\": \"5,3,6,3\", \"action_reward\": [0.038000000000000006, 0, 0.2]}\n",
      "{\"state\": \"4,3,6,3\", \"action_reward\": [0.18816671462399998, 0.0, 0.2]}\n",
      "{\"state\": \"3,3,5,3\", \"action_reward\": [0.15015411199999998, 0.0, 0.238]}\n",
      "{\"state\": \"4,3,5,3\", \"action_reward\": [0.0, 0, 0.2]}\n",
      "{\"state\": \"83,2,84,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"82,1,84,1\", \"action_reward\": [0, 0, 20.0]}\n",
      "{\"state\": \"5,3,7,2\", \"action_reward\": [0.0, 0.0, 0.2]}\n",
      "{\"state\": \"7,2,8,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"8,1,9,1\", \"action_reward\": [0, 0, 20.0]}\n",
      "{\"state\": \"4,3,7,3\", \"action_reward\": [0.0, 0.038000000000000006, 0.0]}\n",
      "{\"state\": \"9,2,10,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"3,3,7,3\", \"action_reward\": [0.0004691556000000001, 0.0013718000000000003, 0.0]}\n",
      "{\"state\": \"2,3,8,3\", \"action_reward\": [0.0, 0.00026064200000000006, 0.0]}\n",
      "{\"state\": \"1,3,8,3\", \"action_reward\": [1.787743478e-06, 4.952198e-05, 0.0]}\n",
      "{\"state\": \"2,3,7,3\", \"action_reward\": [0.0, 0.0013718000000000003, 0.0]}\n",
      "{\"state\": \"2,3,6,3\", \"action_reward\": [0.0, 0.00026064200000000006, 0]}\n",
      "{\"state\": \"2,3,5,3\", \"action_reward\": [0.0013718000000000003, 0.038000000000000006, 0.0]}\n",
      "{\"state\": \"0,3,4,3\", \"action_reward\": [0.0, 0.0013718000000000003, 0.0]}\n",
      "{\"state\": \"1,3,4,3\", \"action_reward\": [0.0, 0.007220000000000002, 0]}\n",
      "{\"state\": \"1,3,3,3\", \"action_reward\": [0.0, 0.0, 0.2]}\n",
      "{\"state\": \"2,3,4,3\", \"action_reward\": [0.14019263999999998, 0.0, 0.2]}\n",
      "{\"state\": \"3,2,4,3\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"1,2,3,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"3,3,8,3\", \"action_reward\": [0.00026064200000000006, 0.007220000000000002, 0.0]}\n",
      "{\"state\": \"4,3,8,3\", \"action_reward\": [0.0011385940000000004, 0.0, 0.007220000000000002]}\n",
      "{\"state\": \"3,3,9,3\", \"action_reward\": [0.0, 0.0013718000000000003, 0]}\n",
      "{\"state\": \"3,3,4,3\", \"action_reward\": [0.0, 0, 0.2]}\n",
      "{\"state\": \"3,3,4,2\", \"action_reward\": [0.0, 0, 0.2]}\n",
      "{\"state\": \"4,3,5,1\", \"action_reward\": [0, 0.0, 20.0]}\n",
      "{\"state\": \"2,3,9,3\", \"action_reward\": [9.4091762e-06, 0.00026064200000000006, 0]}\n",
      "{\"state\": \"1,3,10,3\", \"action_reward\": [1.787743478e-06, 4.952198e-05, 0]}\n",
      "{\"state\": \"0,3,9,3\", \"action_reward\": [0.0, 1.787743478e-06, 0.0]}\n",
      "{\"state\": \"-1,3,9,3\", \"action_reward\": [0.0, 1.787743478e-06, 0.0]}\n",
      "{\"state\": \"0,3,7,3\", \"action_reward\": [0.0, 0.0, 1.787743478e-06]}\n",
      "{\"state\": \"1,3,9,3\", \"action_reward\": [3.3967126082e-07, 0.0, 9.4091762e-06]}\n",
      "{\"state\": \"2,3,10,3\", \"action_reward\": [0.0, 0, 1.4301947824000003e-06]}\n",
      "{\"state\": \"0,3,11,3\", \"action_reward\": [0.0, 9.4091762e-06, 0.0]}\n",
      "{\"state\": \"2,3,11,3\", \"action_reward\": [9.4091762e-06, 7.527340960000001e-06, 0.0]}\n",
      "{\"state\": \"3,3,10,3\", \"action_reward\": [3.16940672e-05, 0.0, 0.0]}\n",
      "{\"state\": \"5,3,8,3\", \"action_reward\": [0.00026064200000000006, 0, 0]}\n",
      "{\"state\": \"4,3,9,3\", \"action_reward\": [0.0010974400000000003, 0, 0]}\n",
      "{\"state\": \"0,3,10,3\", \"action_reward\": [0.0, 9.4091762e-06, 0.0]}\n",
      "{\"state\": \"0,3,8,3\", \"action_reward\": [3.3967126082e-07, 9.4091762e-06, 0.0]}\n",
      "{\"state\": \"-139,3,-137,3\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"-139,3,-138,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"-139,3,-137,1\", \"action_reward\": [0, 0, 20.0]}\n",
      "{\"state\": \"-1,3,1,2\", \"action_reward\": [0, 0.0, 0.2]}\n",
      "{\"state\": \"0,2,1,2\", \"action_reward\": [0, 0.0, 0.2]}\n",
      "{\"state\": \"-1,2,0,1\", \"action_reward\": [0, 0.0, 20.0]}\n",
      "{\"state\": \"0,1,1,1\", \"action_reward\": [0, 0.0, 20.0]}\n",
      "{\"state\": \"0,3,2,3\", \"action_reward\": [0.0, 0.038000000000000006, 0]}\n",
      "{\"state\": \"1,3,5,3\", \"action_reward\": [0.0, 0.007220000000000002, 0]}\n",
      "{\"state\": \"-2,3,8,3\", \"action_reward\": [0.0, 3.3967126082e-07, 0.0]}\n",
      "{\"state\": \"-1,3,7,3\", \"action_reward\": [0.0, 1.787743478e-06, 0]}\n",
      "{\"state\": \"-4,3,4,3\", \"action_reward\": [0.0, 1.787743478e-06, 0]}\n",
      "{\"state\": \"-2,2,-1,3\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"-3,1,-2,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"-3,1,-2,1\", \"action_reward\": [0, 0, 20.0]}\n",
      "{\"state\": \"3,3,7,1\", \"action_reward\": [0.0, 3.8000000000000003, 0]}\n",
      "{\"state\": \"4,3,6,1\", \"action_reward\": [0.722, 0, 20.0]}\n",
      "{\"state\": \"2,3,3,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"2,3,3,1\", \"action_reward\": [0.0, 0, 20.0]}\n",
      "{\"state\": \"1,3,2,3\", \"action_reward\": [0.0, 0.0, 0.2]}\n",
      "{\"state\": \"1,3,2,2\", \"action_reward\": [0.0, 0, 0.9219999999999999]}\n",
      "{\"state\": \"-1,3,2,1\", \"action_reward\": [0.0, 0.0260642, 0]}\n",
      "{\"state\": \"0,3,3,1\", \"action_reward\": [0.0, 0.13718, 0]}\n",
      "{\"state\": \"1,3,2,1\", \"action_reward\": [0.0, 3.8000000000000003, 0]}\n",
      "{\"state\": \"1,3,3,1\", \"action_reward\": [0.0, 3.8000000000000003, 0]}\n",
      "{\"state\": \"1,3,4,1\", \"action_reward\": [0.0, 0, 0.722]}\n",
      "{\"state\": \"0,3,2,1\", \"action_reward\": [0.0, 0.722, 0]}\n",
      "{\"state\": \"-3,3,2,1\", \"action_reward\": [0.0, 0.00094091762, 0.0]}\n",
      "{\"state\": \"-3,3,3,1\", \"action_reward\": [3.3967126082e-05, 0.0, 0.0]}\n",
      "{\"state\": \"-2,3,3,1\", \"action_reward\": [0.0001787743478, 0.004952198, 0.0]}\n",
      "{\"state\": \"0,3,5,1\", \"action_reward\": [0.0, 0.004952198, 0.0]}\n",
      "{\"state\": \"1,3,5,1\", \"action_reward\": [0.0, 0, 0.13718]}\n",
      "{\"state\": \"-4,3,2,1\", \"action_reward\": [0.0, 0.0001787743478, 0.0]}\n",
      "{\"state\": \"-27,2,-25,1\", \"action_reward\": [0.0, 0, 20.0]}\n",
      "{\"state\": \"0,3,1,3\", \"action_reward\": [0.038000000000000006, 0.0, 0]}\n",
      "{\"state\": \"0,3,1,1\", \"action_reward\": [0.004952198, 0, 0]}\n",
      "{\"state\": \"1,3,6,1\", \"action_reward\": [0.00094091762, 0, 0.0260642]}\n",
      "{\"state\": \"0,3,7,1\", \"action_reward\": [0, 0.004952198, 0.0]}\n",
      "{\"state\": \"-13,2,-11,1\", \"action_reward\": [0, 0, 20.0]}\n",
      "{\"state\": \"-1,3,3,3\", \"action_reward\": [0.0, 0.00026064200000000006, 0.0]}\n",
      "{\"state\": \"-2,3,3,3\", \"action_reward\": [0.0, 4.952198e-05, 0.0]}\n",
      "{\"state\": \"-1,3,2,3\", \"action_reward\": [0.0, 0, 4.952198e-05]}\n",
      "{\"state\": \"21,3,23,3\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"21,3,22,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"17,3,19,1\", \"action_reward\": [0, 0.0, 20.0]}\n",
      "{\"state\": \"-1,3,0,3\", \"action_reward\": [0.0, 0.0, 0.2]}\n",
      "{\"state\": \"-4,3,-3,3\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"-4,3,-2,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"-1,2,0,3\", \"action_reward\": [0.0, 0, 0.2]}\n",
      "{\"state\": \"-1,3,0,2\", \"action_reward\": [0, 0, 0.2]}\n",
      "{\"state\": \"3,3,11,3\", \"action_reward\": [0, 0, 9.4091762e-06]}\n",
      "{\"state\": \"-3,3,3,3\", \"action_reward\": [0.0, 9.4091762e-06, 0]}\n",
      "{\"state\": \"-4,3,3,3\", \"action_reward\": [0, 1.787743478e-06, 0.0]}\n",
      "{\"state\": \"-3,3,2,3\", \"action_reward\": [0.0, 9.4091762e-06, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "agent = agent_0\n",
    "\n",
    "for k in agent.q_dict:\n",
    "    if max(agent.q_dict[k]) > 0:\n",
    "        print(json.dumps({\"state\": k, \"action_reward\": agent.q_dict[k]}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda_python36]",
   "language": "python",
   "name": "conda-env-conda_python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
